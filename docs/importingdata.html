<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Importing Spatial Data</title>

<script src="site_libs/header-attrs-2.30/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">VoltRon</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="tutorials.html">Explore</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Vignette
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">Spatial Data Integration</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="registration.html">Spatial Data Alignment</a>
        </li>
        <li>
          <a href="multiomic.html">Multi-omic Integration</a>
        </li>
        <li>
          <a href="nicheclustering.html">Niche Clustering</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">Downstream Analysis</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="roianalysis.html">ROI Analysis</a>
        </li>
        <li>
          <a href="spotanalysis.html">Cell/Spot Analysis</a>
        </li>
        <li>
          <a href="moleculeanalysis.html">Molecule Analysis</a>
        </li>
        <li>
          <a href="pixelanalysis.html">Pixels (Image Only) Analysis</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">Utilities</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="interactive.html">Interactive Utilities</a>
        </li>
        <li>
          <a href="importingdata.html">Importing Spatial Data</a>
        </li>
        <li>
          <a href="voltronobjects.html">Working with VoltRon Objects</a>
        </li>
        <li>
          <a href="conversion.html">Converting VoltRon Objects</a>
        </li>
        <li>
          <a href="ondisk.html">OnDisk-based Analysis Utilities</a>
        </li>
      </ul>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-envelope-o"></span>
     
    Contact
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://bioinformatics.mdc-berlin.de">Altuna Lab/BIMSB Bioinfo</a>
    </li>
    <li>
      <a href="https://www.mdc-berlin.de/landthaler">Landthaler Lab/BIMSB</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-github"></span>
     
    GitHub
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://github.com/BIMSBbioinfo/VoltRon">VoltRon</a>
    </li>
    <li>
      <a href="https://github.com/BIMSBbioinfo">BIMSB Bioinfo</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Importing Spatial Data</h1>

</div>


<style>
.title{
  display: none;
}
body {
  text-align: justify
}
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
table, th, td {
  border-collapse: collapse;
  align-self: center;
  padding-right: 10px;
  padding-left: 10px;
}
</style>
<style type="text/css">
.watch-out {
  color: black;
}
</style>
<p><br></p>
<div id="importing-spatial-datasets" class="section level1">
<h1>Importing Spatial Datasets</h1>
<p>VoltRon is an end-to-end spatial omics analysis package that supports
a large selection of spatial data resolutions. Currently, there exists a
considerable amount of spatial omics technologies that generate datasets
whose omics profiles are spatially resolved.</p>
<p>VoltRon objects are compatible with readouts of almost all of these
technologies where we provide a selection of built-in functions to help
users constructing VoltRon objects with ease. In this tutorial, we will
review these spatial omics instruments and the functions available
within the VoltRon package to import their readouts.</p>
<p></br></p>
<div id="visium-10x-genomics" class="section level2">
<h2>Visium (10x Genomics)</h2>
<p></br></p>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/visium_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: The Visium Spatial Gene Expression Slide (<a
href="https://www.10xgenomics.com/"
class="uri">https://www.10xgenomics.com/</a>) </em>
</p>
<p>10x Genomics <a
href="https://www.10xgenomics.com/products/spatial-gene-expression">Visium</a>
Spatial Gene Expression Platform incorporates in situ arrays
(i.e. spots) to capture spatial localization of omics profiles where
these spots are of 55 <span class="math inline">\(\mu\)</span>m in
diameter and constitute a grid that covers a significant portion of a
tissue section placed on the slide of the instrument.</p>
<p>We will use the readouts of <strong>Visium CytAssist</strong>
platform that was derived from a single tissue section of a breast
cancer sample. More information on the Visium CytAssist data and the
study can be also be found on the <a
href="https://www.biorxiv.org/content/10.1101/2022.10.06.510405v1">bioRxiv
preprint</a>. You can download the data from the <a
href="https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast">10x
Genomics website</a> (specifically, import the <strong>Visium
Spatial</strong> data).</p>
<p>Before we start, Visium readouts require <strong>rhdf5</strong>
package to be installed.</p>
<pre class="r watch-out"><code>if(!requireNamespace(&quot;rhdf5&quot;))
  BiocManager::install(&quot;rhdf5&quot;)</code></pre>
<p>We use the <strong>importVisium</strong> function to import the
Visium readouts and create a VoltRon object. Here, we point to the
folder of all the files with <strong>dir.path</strong> argument and also
determine the name of this sample (<strong>sample_name</strong>).</p>
<pre class="r watch-out"><code>library(VoltRon)
Vis_R1 &lt;- importVisium(dir.path = &quot;Visium/&quot;, sample_name = &quot;VisiumR1&quot;)</code></pre>
<pre><code>VoltRon Object 
VisiumR1: 
  Layers: Section1 
Assays: Visium(Main) </code></pre>
<p></br></p>
<p>While importing the readouts, we can also determine the name of the
assay as well as the name of the image. The
<strong>SampleMetadata</strong> function summarizes the entire
collection of assays, layers (sections) and samples (tissue blocks)
within the R object.</p>
<pre class="r watch-out"><code>Vis_R1 &lt;- importVisium(dir.path = &quot;Visium/&quot;, sample_name = &quot;VisiumR1&quot;, 
                       assay_name = &quot;Visium_assay&quot;, image_name = &quot;H&amp;E_stain&quot;)
SampleMetadata(Vis_R1)</code></pre>
<pre><code>              Assay    Layer   Sample
Assay1 Visium_assay Section1 VisiumR1</code></pre>
<p></br></p>
<p>The current VoltRon object has only one assay associated with a
single layer and a tissue block, and the image of this assay is
currently the “H&amp;E_stain”.</p>
<pre class="r watch-out"><code>vrImageNames(Vis_R1)</code></pre>
<pre><code>[1] &quot;H&amp;E_stain&quot;</code></pre>
<p><br></p>
<p>Although by default the <strong>importVisium</strong> function
selects the low resolution image, you can select the higher resolution
one using <strong>resolution_level=“hires”</strong></p>
<pre class="r watch-out"><code>Vis_R1 &lt;- importVisium(dir.path = &quot;Visium/&quot;, sample_name = &quot;VisiumR1&quot;, resolution_level=&quot;hires&quot;)</code></pre>
<p><br></p>
</div>
<div id="visiumhd-10x-genomics" class="section level2">
<h2>VisiumHD (10x Genomics)</h2>
<p></br></p>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/visiumhd_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> <a
href="https://www.10xgenomics.com/products/visium-hd-spatial-gene-expression"
class="uri">https://www.10xgenomics.com/products/visium-hd-spatial-gene-expression</a>
</em>
</p>
<p>10x Genomics <a
href="https://www.10xgenomics.com/products/visium-hd-spatial-gene-expression">VisiumHD</a>
Spatial Gene Expression Platform contains two 6.5 x 6.5 mm Capture Areas
with a continuous lawn of oligonucleotides arrayed in millions of 2 x 2
µm barcoded squares without gaps, achieving single cell–scale spatial
resolution. The data is output at 2 µm, as well as multiple bin sizes.
The 8 x 8 µm bin is the recommended starting point for visualization and
analysis.</p>
<p>We will use the readouts of <strong>Visium CytAssist</strong>
platform that was derived from a single tissue section of a breast
cancer sample. More information on the Visium CytAssist data and the
study can be also be found on the <a
href="https://www.biorxiv.org/content/10.1101/2022.10.06.510405v1">bioRxiv
preprint</a>. You can download the data from the <a
href="https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast">10x
Genomics website</a> (specifically, import the <strong>Visium
Spatial</strong> data).</p>
<p>Before we start, VisiumHD readouts require a number of Bioconductor
and R packages to be installed.</p>
<pre class="r watch-out"><code>if(!requireNamespace(&quot;arrow&quot;))
  install.packages(&quot;arrow&quot;)
if(!requireNamespace(&quot;rhdf5&quot;))
  BiocManager::install(&quot;rhdf5&quot;)</code></pre>
<p>We use the <strong>importVisiumHD</strong> function to import the
Visium readouts and create a VoltRon object. Here, we point to the
folder of all the files with <strong>dir.path</strong> argument and also
determine the name of this sample (<strong>sample_name</strong>).</p>
<pre class="r watch-out"><code>library(VoltRon)
hddata &lt;- importVisiumHD(dir.path = &quot;VisiumHD/outs/&quot;, 
                         sample_name = &quot;VisiumHD&quot;)</code></pre>
<p><br></p>
<p>The VisiumHD readouts provide multiple bin sizes which are aggregated
versions of the original 2<span class="math inline">\(\mu\)</span>m
<span class="math inline">\(x\)</span> 2<span
class="math inline">\(\mu\)</span>m capture spots. The default bin sizes
are <strong>(i)</strong> 2<span class="math inline">\(\mu\)</span>m
<span class="math inline">\(x\)</span> 2<span
class="math inline">\(\mu\)</span>m, <strong>(ii)</strong> 8<span
class="math inline">\(\mu\)</span>m <span
class="math inline">\(x\)</span> 8<span
class="math inline">\(\mu\)</span>m and <strong>(iii)</strong> 16<span
class="math inline">\(\mu\)</span>m <span
class="math inline">\(x\)</span> 16<span
class="math inline">\(\mu\)</span>m. Although by default the
<strong>importVisium</strong> function selects the low resolution image,
you can select the higher resolution one using
<strong>resolution_level=“hires”</strong>.</p>
<pre class="r watch-out"><code>hddata &lt;- importVisiumHD(dir.path = &quot;VisiumHD/outs/&quot;, 
                         bin.size = &quot;16&quot;, 
                         resolution_level = &quot;hires&quot;, 
                         sample_name = &quot;VisiumHD&quot;)</code></pre>
<p><br></p>
</div>
<div id="xenium-10x-genomics" class="section level2">
<h2>Xenium (10x Genomics)</h2>
<p></br></p>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/xenium_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a
href="https://www.biorxiv.org/content/10.1101/2022.10.06.510405v2"
class="uri">https://www.biorxiv.org/content/10.1101/2022.10.06.510405v2</a>
</em>
</p>
<p>The 10x Genomics <a
href="https://www.10xgenomics.com/platforms/xenium">Xenium In Situ</a>
provides spatial localization of both (i) transcripts from a few hundred
number of genes as well as (ii) the single cells with transcriptomics
profiles.</p>
<p>We will use the readouts of a single Xenium platform replicate that
was derived from a single tissue section of a breast cancer sample. More
information on the Xenium data and the study can be also be found on the
<a
href="https://www.biorxiv.org/content/10.1101/2022.10.06.510405v1">bioRxiv
preprint</a>. You can download the data from the <a
href="https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast">10x
Genomics website</a> (specifically, import the <strong>In Situ Replicate
1</strong> data).</p>
<p>Before we start, Xenium readouts require a number of Bioconductor and
R packages to be installed. RBioFormats requires rJava and JDK
installed, see <a
href="https://github.com/BIMSBbioinfo/VoltRon?tab=readme-ov-file#dependencies">dependencies</a>
section for more information.</p>
<pre class="r watch-out"><code>if(!requireNamespace(&quot;RBioFormats&quot;))
  BiocManager::install(&quot;RBioFormats&quot;)
if(!requireNamespace(&quot;arrow&quot;))
  install.packages(&quot;arrow&quot;)
if(!requireNamespace(&quot;rhdf5&quot;))
  BiocManager::install(&quot;rhdf5&quot;)</code></pre>
<p>We use the <strong>importXenium</strong> function to import the
Xenium readouts and create a VoltRon object. Here, we point to the
folder of all the files with <strong>dir.path</strong> argument and also
determine the name of this sample (<strong>sample_name</strong>).</p>
<pre class="r watch-out"><code>library(VoltRon)
Xen_R1 &lt;- importXenium(&quot;Xenium_R1/outs&quot;, sample_name = &quot;XeniumR1&quot;)</code></pre>
<pre><code>VoltRon Object 
XeniumR1: 
  Layers: Section1 
Assays: Xenium(Main) </code></pre>
<p></br></p>
<p>You can use the <strong>import_molecules</strong> argument to import
positions and features of the transcripts along with the single cell
profiles.</p>
<pre class="r watch-out"><code>Xen_R1 &lt;- importXenium(&quot;Xenium_R1/outs&quot;, sample_name = &quot;XeniumR1&quot;, import_molecules = TRUE)
Xen_R1</code></pre>
<pre><code>VoltRon Object 
XeniumR1: 
  Layers: Section1 
Assays: Xenium(Main) Xenium_mol </code></pre>
<p>The <strong>SampleMetadata</strong> function summarizes the entire
collection of assays, layers (sections) and samples (tissue blocks)
within the R object. In this case, the function will generate two assays
in a single layer where one is a “cell” assay and the other is a
“molecule assay”.</p>
<pre class="r watch-out"><code>SampleMetadata(Xen_R1)</code></pre>
<pre><code>            Assay    Layer   Sample
Assay1     Xenium Section1 XeniumR1
Assay2 Xenium_mol Section1 XeniumR1</code></pre>
<p></br></p>
<p>The Xenium in situ platform provides multiple resolution of the same
Xenium slide which can be parsed from the OME.TIFF image file of DAPI
stained tissue section (e.g. morphology_mip.ome.tif). The
<strong>resolution_level</strong> argument determines the resolution of
the DAPI image generated from the OME.TIFF file. More information on
resolution levels can be found <a
href="https://kb.10xgenomics.com/hc/en-us/articles/11636252598925-What-are-the-Xenium-image-scale-factors-">here</a>.</p>
<pre class="r watch-out"><code>Xen_R1 &lt;- importXenium(&quot;Xenium_R1/outs&quot;, sample_name = &quot;XeniumR1&quot;, import_molecules = TRUE, 
                       resolution_level = 4, overwrite_resolution = TRUE)
vrImages(Xen_R1, assay = &quot;Xenium&quot;)</code></pre>
<pre><code># A tibble: 1 × 7
  format width height colorspace matte filesize density
  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  
1 PNG     4427   3222 Gray       FALSE        0 72x72  </code></pre>
<p></br></p>
<p>Users can also decide to ignore OME.TIFF file and images, hence only
cells and molecules would be imported.</p>
<pre class="r watch-out"><code>Xen_R1 &lt;- importXenium(&quot;Xenium_R1/outs&quot;, sample_name = &quot;XeniumR1&quot;, import_molecules = TRUE, 
                       use_image = FALSE)</code></pre>
<p></br></p>
</div>
<div id="geomx-nanostring" class="section level2">
<h2>GeoMx (NanoString)</h2>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/geomx_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a
href="https://www.biochain.com/nanostring-geomx-digital-spatial-profiling/"
class="uri">https://www.biochain.com/nanostring-geomx-digital-spatial-profiling/</a>
</em>
</p>
<p>The <a
href="https://nanostring.com/products/geomx-digital-spatial-profiler/geomx-dsp-overview/">Nanostring’s
GeoMx Digital Spatial Profiler</a> is a high-plex spatial profiling
technology which produces segmentation-based protein and RNA assays. The
instrument allows users to select regions of interest (ROIs) from
fluorescent microscopy images that capture the morphological context of
the tissue. These are ROIs are then used to generate transcriptomics or
proteomics profiles.</p>
<p>We will import the ROI profiles generated from the GeoMx scan area
where COVID-19 lung tissues were fitted into. See <a
href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE190732">GSE190732</a>
for more information on this study.</p>
<p>Here is the usage of <strong>importGeoMx</strong> function and
necessary files for this example:</p>
<table>
<tr>
<th>
Argument
</th>
<th>
Description
</th>
<th>
Link
</th>
</tr>
<tr>
<td>
dcc.path
</td>
<td>
The path to DCC files directory
</td>
<td>
<a href="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/ROIanalysis/GeoMx/DCC-20230427.zip">DDC
files</a>
</td>
</tr>
<tr>
<td>
pkc.file
</td>
<td>
GeoMx™ DSP configuration file
</td>
<td>
<a href="https://nanostring.com/wp-content/uploads/Hs_R_NGS_WTA_v1.0.pkc_.zip">Human
RNA Whole Transcriptomics Atlas for NGS</a>
</td>
</tr>
<tr>
<td>
summarySegment
</td>
<td>
Segment summary table (.xls or .csv)
</td>
<td>
<a href="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/ROIanalysis/GeoMx/segmentSummary.csv">
ROI Metadata file </a>
</td>
</tr>
<tr>
<td>
image
</td>
<td>
The Morphology Image of the scan area
</td>
<td>
<a href="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/ROIanalysis/GeoMx/Lu1A1B5umtrueexp.tif">
Image file </a>
</td>
</tr>
<tr>
<td>
ome.tiff
</td>
<td>
The OME.TIFF Image of the scan area
</td>
<td>
<a href="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/ROIanalysis/GeoMx/Lu1A1B5umtrueexp.ome.tiff">
OME.TIFF file </a>
</td>
</tr>
<tr>
<td>
</td>
<td>
The OME.TIFF Image XML file
</td>
<td>
<a href="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/ROIanalysis/GeoMx/Lu1A1B5umtrueexp.ome.tiff.xml" download target="_blank">
OME.TIFF (XML) file </a>
</td>
</tr>
</table>
<p></br></p>
<pre class="r watch-out"><code>library(VoltRon)
GeoMxR1 &lt;- importGeoMx(dcc.path = &quot;DCC-20230427/&quot;, 
                       pkc.file = &quot;Hs_R_NGS_WTA_v1.0.pkc&quot;,
                       summarySegment = &quot;segmentSummary.csv&quot;,
                       image = &quot;Lu1A1B5umtrueexp.tif&quot;,
                       ome.tiff = &quot;Lu1A1B5umtrueexp.ome.tiff&quot;,
                       sample_name = &quot;GeoMxR1&quot;)</code></pre>
<p>The OME.TIFF file here provides the ROI coordinates within the
embedded XML metadata. We can also incorporate the
<strong>RBioFormats</strong> package to extract the XML metadata from
the OME.TIFF file. RBioFormats requires rJava and JDK installed, see <a
href="https://github.com/BIMSBbioinfo/VoltRon?tab=readme-ov-file#dependencies">dependencies</a>
section for more information.</p>
<pre class="r watch-out"><code>if(!requireNamespace(&quot;RBioFormats&quot;))
  BiocManager::install(&quot;RBioFormats&quot;)
library(RBioFormats)

# alternatively you can use RBioFormats to create an xml file
ome.tiff.xml &lt;- RBioFormats::read.omexml(&quot;data/GeoMx/Lu1A1B5umtrueexp.ome.tiff&quot;)
write(ome.tiff.xml, file = &quot;data/GeoMx/Lu1A1B5umtrueexp.ome.tiff.xml&quot;)</code></pre>
<p>The <strong>ome.tiff</strong> argument also accepts the path to this
XML file.</p>
<pre class="r watch-out"><code>GeoMxR1 &lt;- importGeoMx(dcc.path = &quot;DCC-20230427/&quot;,
                       pkc.file = &quot;Hs_R_NGS_WTA_v1.0.pkc&quot;,
                       summarySegment = &quot;segmentSummary.csv&quot;,
                       image = &quot;Lu1A1B5umtrueexp.tif&quot;,
                       ome.tiff = &quot;Lu1A1B5umtrueexp.ome.tiff.xml&quot;,
                       sample_name = &quot;GeoMxR1&quot;)</code></pre>
<p></br></p>
</div>
<div id="cosmx-nanostring" class="section level2">
<h2>CosMx (NanoString)</h2>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/cosmx_summary.png" class="center">
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/cosmx_summary2.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a
href="https://www.biorxiv.org/content/10.1101/2021.11.03.467020v1.full"
class="uri">https://www.biorxiv.org/content/10.1101/2021.11.03.467020v1.full</a>
</em>
</p>
<p>The <a
href="https://nanostring.com/products/cosmx-spatial-molecular-imager/cosmx-smi-single-cell-imaging-de/">Nanostring’s
CosMx Spatial Molecular Imaging</a> platform is a high-plex spatial
multiomics technology that captures the spatial localization of both (i)
transcripts from thousands of genes as well as (ii) the single cells
with transcriptomics and proteomics profiles.</p>
<p>We will use the readouts from two slides of a single CosMx
experiment. You can download the data from the <a
href="https://nanostring.com/products/cosmx-spatial-molecular-imager/ffpe-dataset/cosmx-smi-mouse-brain-ffpe-dataset/">Nanostring
website</a>.</p>
<p>We use the <strong>importCosMx</strong> function to import the CosMx
readouts and create a VoltRon object. Here, we point to the folder of
the <a href="https://tiledb.com/">TileDB</a> array that stores feature
matrix as well as the transcript metadata.</p>
<pre class="r watch-out"><code>CosMxR1 &lt;- importCosMx(tiledbURI = &quot;MuBrainDataRelease/&quot;)</code></pre>
<pre><code>VoltRon Object 
Slide1: 
  Layers: Section1 
Slide2: 
  Layers: Section1 
Assays: CosMx(Main) </code></pre>
<p>You can use the <strong>import_molecules</strong> argument to import
positions and features of the transcripts along with the single cell
profiles.</p>
<pre class="r watch-out"><code>CosMxR1 &lt;- importCosMx(tiledbURI = &quot;MuBrainDataRelease/&quot;, import_molecules = TRUE)</code></pre>
<p></br></p>
</div>
<div id="stomics-mgi" class="section level2">
<h2>STOmics (MGI)</h2>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/stomics_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a href="https://bgi-australia.com.au/stomics"
class="uri">https://bgi-australia.com.au/stomics</a> </em>
</p>
<p>Before importing the STOmics data to VoltRon, we first convert
STOmics readouts to an h5ad file using the <strong>stereopy</strong>
Python module. For more information, visit <a
href="https://stereopy.readthedocs.io/en/latest/Tutorials/Format_Conversion.html">https://stereopy.readthedocs.io/</a>.
See <a
href="https://stereopy.readthedocs.io/en/latest/content/00_Installation.html">here</a>
for instructions on how to install <strong>stereopy</strong>.</p>
<pre class="python watch-out"><code>import stereo as st
import warnings
warnings.filterwarnings(&#39;ignore&#39;)

# read the GEF file
data_path = &#39;./SS200000135TL_D1.tissue.gef&#39;
data = st.io.read_gef(file_path=data_path, bin_size=50)
data.tl.raw_checkpoint()

# remember to set flavor as scanpy
adata = st.io.stereo_to_anndata(data, flavor=&#39;scanpy&#39;, output=&#39;sample.h5ad&#39;)</code></pre>
<p><br></p>
<p>We use the <strong>importSTOmics</strong> function to import the
STOmics readouts and create a VoltRon object. Here, we point to the
folder an h5ad file generated using the
<strong>stereo.io.stereo_to_anndata</strong> method previously.</p>
<pre class="r watch-out"><code>vrdata &lt;- importSTOmics(h5ad.path = &quot;sample.h5ad&quot;)</code></pre>
<pre><code>VoltRon Object 
Sample1: 
  Layers: Section1 
Assays: STOmics(Main) </code></pre>
<p></br></p>
</div>
<div id="geneps-spatial-genomics" class="section level2">
<h2>GenePS (Spatial Genomics)</h2>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/geneps_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a href="https://spatialgenomics.com/applications/"
class="uri">https://spatialgenomics.com/applications/</a> </em>
</p>
<p>We use the <strong>importGenePS</strong> function to import the
GenePS (<a href="https://spatialgenomics.com/product/">Spatial
Genomics</a>) readouts and create a VoltRon object. You can use the
<strong>import_molecules</strong> argument to import positions and
features of the transcripts along with the single cell profiles. The
<strong>resolution_level</strong> argument determines the resolution of
the DAPI image generated from the TIFF file.</p>
<pre class="r watch-out"><code>vrdata &lt;- importGenePS(dir.path = &quot;out/&quot;, import_molecules = TRUE, resolution_level = 7)</code></pre>
<pre><code>VoltRon Object 
Sample1: 
  Layers: Section1 
Assays: GenePS(Main) GenePS_mol</code></pre>
<p></br></p>
</div>
<div id="phenocycler-akoya" class="section level2">
<h2>PhenoCycler (Akoya)</h2>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/phenocycler_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a
href="https://tep.cancer.illinois.edu/phenocycler-fusion-system/"
class="uri">https://tep.cancer.illinois.edu/phenocycler-fusion-system/</a>
</em>
</p>
<p>We use the <strong>importPhenoCycler</strong> function to import the
PhenoCycler (<a href="https://www.akoyabio.com/">Akoya Biosciences</a>)
readouts and create a VoltRon object. The function supports multiple
readouts types depending on how the readouts were generated, this is
controlled by the <strong>type</strong> arguement. For more information
on all arguements of the function, see
<strong>help(importPhenoCycler)</strong>.</p>
<p>We used the Human FFPE tonsil tissue example with 83000 cells which
could be found <a
href="https://akoya.app.box.com/s/lqaz1eyefni57sfynveh03e9sdy4aeuk">here</a>.
You have to download the contents and <strong>dir.path</strong>
arguement should be set to the location of the
<strong>Example-dataset-for-MAV</strong> folder.</p>
<pre class="r watch-out"><code>vr_pheno &lt;- importPhenoCycler(dir.path = &quot;Example-dataset-for-MAV/&quot;, type = &quot;processor&quot;, 
                              sample_name = &quot;Tonsil18AB&quot;)</code></pre>
<pre><code>VoltRon Object 
Tonsil18AB: 
  Layers: Section1 
Assays: PhenoCycler(Main) </code></pre>
<p></br></p>
</div>
<div id="openst" class="section level2">
<h2>OpenST</h2>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/openst_summary.jpg" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a
href="https://www.cell.com/cell/fulltext/S0092-8674(24)00636-6"
class="uri">https://www.cell.com/cell/fulltext/S0092-8674(24)00636-6</a>
</em>
</p>
<p>We use the <strong>importOpenST</strong> function to import the
OpenST <a
href="https://rajewsky-lab.github.io/openst/latest/">https://rajewsky-lab.github.io/openst/latest/</a>
readouts and create a VoltRon object. The function will parse each
section from the output h5ad file, define it as an independent assay in
a single layer where these layers are ordered in a single tissue
block.</p>
<p>We use the metastatic lymph node example that is deposited to
NCBI/GEO (<a
href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE251926">GSE251926</a>).
Please use the
<strong>GSE251926_metastatic_lymph_node_3d.h5ad.gz</strong> file and
unzip it to use the importOpenST function below.</p>
<pre class="r watch-out"><code>vr_openst &lt;- importOpenST(h5ad.path = &quot;GSE251926_metastatic_lymph_node_3d.h5ad&quot;, 
                          sample_name = &quot;MLN_3D&quot;)</code></pre>
<pre><code>VoltRon Object 
MLN_3D: 
  Layers: Section1 Section2 Section3 Section4 Section5 Section6 Section7 Section8 Section9 Section10 Section11 Section12 Section13 Section14 Section15 Section16 Section17 Section18 Section19 
Assays: OpenST(Main) </code></pre>
<p></br></p>
</div>
<div id="dbit-seq" class="section level2">
<h2>DBIT-Seq</h2>
<img width="70%" height="70%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/dbitseq_summary.jpg" class="center">
<p style="margin-left:3.4cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: <a
href="https://www.cell.com/cell/fulltext/S0092-8674(20)31390-8"
class="uri">https://www.cell.com/cell/fulltext/S0092-8674(20)31390-8</a>
</em>
</p>
<p>We use the <strong>importDBITSeq</strong> function to import the
DBIT-Seq <a
href="https://www.cell.com/cell/fulltext/S0092-8674(20)31390-8">https://www.cell.com/cell/fulltext/S0092-8674(20)31390-8</a>
readouts and create a VoltRon object. The default path to the rna count
matrix is accompanied by the path to the protein count matrix, which is
optional. The <strong>size</strong> parameter here determines the size
of each square pixel on the DBIT-Seq slide (default is 10<span
class="math inline">\(\mu\)</span>m).</p>
<p>We use the example with developing eye field in a E10 mouse embryo
using 10-μm microfluidic (sample id: 0719cL for RNA, and 0719aL for
Protein) channels that is deposited to NCBI/GEO (<a
href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE137986">GSE137986</a>).</p>
<pre class="r watch-out"><code>vr_dbit &lt;- importDBITSeq(path.rna = &quot;GSM4189615_0719cL.tsv&quot;, 
                         path.prot = &quot;GSM4202309_0719aL.tsv&quot;, 
                         size = 10, sample_name = &quot;E10_Eye_2&quot;, image_name = &quot;main&quot;)</code></pre>
<pre><code>VoltRon Object 
E10_Eye_2: 
  Layers: Section1 
Assays: DBIT-Seq-RNA(Main) DBIT-Seq-Prot </code></pre>
<p></br></p>
</div>
<div id="st-data" class="section level2">
<h2>ST data</h2>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/stdata_summary.png" class="center">
<p style="margin-left: 1.2cm; margin-top:0.2cm; font-size:80%;">
<em> Image Credit: Ståhl, et. al (2016). Visualization and analysis of
gene expression in tissue sections by spatial transcriptomics. Science,
353(6294), 78-82. </em>
</p>
<p>We demonstrate importing the original Spatial Transcriptomics (ST)
datasets by formulating custom spot-level spatial transcriptomics
datasets. We will use the <strong>formVoltRon</strong> function
directly. We use the example provided by the <a
href="https://doi.org/10.5281/zenodo.4751624">https://doi.org/10.5281/zenodo.4751624</a>.
For more information you can also check the paper <a
href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8516894/">here</a>.</p>
<p>We first import and manipulate count matrices and spot coordinates
from the provided output files. Here we only demonstrate building a
custom spot-level VoltRon object for the section “A1”, however the
remaining sections can be imported using the same method.</p>
<pre class="r watch-out"><code># count matrix
raw.data &lt;- read.table(&quot;A1.tsv&quot;, header = TRUE, sep = &quot;\t&quot;)
spatialentities &lt;- raw.data$X
raw.data &lt;- raw.data[,-1]
raw.data &lt;- t(as.matrix(raw.data))

# coords 
coords &lt;- read.table(&quot;A1_selection.tsv&quot;, header = TRUE, sep = &quot;\t&quot;)
rownames(coords) &lt;- paste(coords$x, coords$y, sep = &quot;x&quot;)
coords &lt;- coords[spatialentities,]
coords &lt;- coords[,c(&quot;pixel_x&quot;, &quot;pixel_y&quot;)]
colnames(coords) &lt;- c(&quot;x&quot;, &quot;y&quot;)</code></pre>
<p>The image can be imported using the <strong>magick</strong>
package.</p>
<pre class="r watch-out"><code>library(magick)
img &lt;- magick::image_read(&quot;HE/A1.jpg&quot;)
img_info &lt;- magick::image_info(img)</code></pre>
<p>Before we form the VoltRon object, we should define the parameters
for spot-level datasets. Here, we provide</p>
<ul>
<li>the radius of a spot in the physical space
(i.e. <strong>spot.radius</strong>)</li>
<li>the radius of a spot for visualization
(i.e. <strong>vis.spot.radius</strong>)</li>
<li>The distance to the nearest spot, to be used for spatial
neighborhood calculation
(i.e. <strong>nearestpost.distance</strong>)</li>
</ul>
<p>The scaling parameter (scale_param) is required to overlay
localization and distances of spots to the coordinate system of the
imported image. Here,</p>
<ul>
<li>the width of a ST slide is of 6200<span
class="math inline">\(\mu\)</span>m,</li>
<li>the diameter of a spot is 100<span
class="math inline">\(\mu\)</span>m (hence a radius of 50<span
class="math inline">\(\mu\)</span>m) and</li>
<li>the center-to-center distance between two spots is 200<span
class="math inline">\(\mu\)</span>m.</li>
<li>Each spot has at most 8 neighboring spots including vertically,
horizontally and diagonally adjacent spots.</li>
</ul>
<pre class="r watch-out"><code>scale_param &lt;- img_info$width/6200
params &lt;- list(
  spot.radius = 50*(scale_param),
  vis.spot.radius = 100*(scale_param),
  nearestpost.distance = (200*sqrt(2) + 50)*scale_param
)</code></pre>
<p>Now we can combine all components into a VoltRon object. We should
also flip the coordinates of spots vertically after creating the
object.</p>
<pre class="r watch-out"><code># make voltron object
stdata &lt;- formVoltRon(data = raw.data, image = img, coords = coords, assay.type = &quot;spot&quot;, 
                      params = params, sample_name = &quot;A1&quot;)
stdata &lt;- flipCoordinates(stdata)</code></pre>
<p>We can now visualize spots and the adjacency between these spots
simultaneously.</p>
<pre class="r watch-out"><code>stdata &lt;- getSpatialNeighbors(stdata, method = &quot;radius&quot;)
vrSpatialPlot(stdata, graph.name = &quot;radius&quot;, crop = T)</code></pre>
<p><img width="75%" height="75%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/stdata_summary_plot.png" class="center"></p>
<p><br></p>
</div>
<div id="custom-voltron-objects" class="section level2">
<h2>Custom VoltRon objects</h2>
<p>VoltRon incorporates the <strong>formVoltRon</strong> function to
assemble each component of a spatial omics assay into a VoltRon object.
Here:</p>
<ul>
<li><strong>the feature matrix</strong>: the <em> pxn </em> feature to
point matrix for raw counts and omics profiles</li>
<li><strong>metadata</strong>: the metadata table</li>
<li><strong>image</strong>: An image or a list of images with names
associated to channel</li>
<li><strong>coordinates</strong>: xy-Coordinates of spatial points</li>
<li><strong>segments</strong>: the list of xy-Coordinates of each
spatial point</li>
</ul>
<p>can individually be prepared before executing formVoltRon.</p>
<p>We will use a single image based proteomics assay to demonstrate
building custom VoltRon objects. Specifically, we use cells
characterized by <strong>multi-epitope ligand cartography
(MELC)</strong> with a panel of 44 parameters. We use the already
segmented cells on which expression of <strong>43 protein
features</strong> (excluding DAPI) were mapped to these cells.</p>
<p>VoltRon also provides support for imaging based proteomics assays. In
this next use case, we analyze cells characterized by
<strong>multi-epitope ligand cartography (MELC)</strong> with a panel of
44 parameters. We use the already segmented cells on which expression of
<strong>43 protein features</strong> (excluding DAPI) were mapped to
these cells. You can download the files below <a
href="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/ImportData/custom_vr_object.zip">here</a>.</p>
<pre class="r watch-out"><code>library(magick)

# feature x cell matrix
intensity_data &lt;- read.table(&quot;intensities.tsv&quot;, sep = &quot;\t&quot;)
intensity_data &lt;- as.matrix(intensity_data)

# metadata
metadata &lt;- read.table(&quot;metadata.tsv&quot;, sep = &quot;\t&quot;)

# coordinates
coordinates &lt;- read.table(&quot;coordinates.tsv&quot;, sep = &quot;\t&quot;)
coordinates &lt;- as.matrix(coordinates)

# image
library(magick)
image &lt;- image_read(&quot;DAPI.tif&quot;)

# create VoltRon object
vr_object&lt;- formVoltRon(data = intensity_data,
                        metadata = metadata,
                        image = image,
                        coords = coordinates,
                        main.assay = &quot;MELC&quot;,
                        assay.type = &quot;cell&quot;,
                        sample_name = &quot;control_case_3&quot;,
                        image_name = &quot;DAPI&quot;)
vr_object</code></pre>
<pre><code>VoltRon Object 
control_case_3: 
  Layers: Section1 
Assays: MELC(Main) </code></pre>
<p>VoltRon can store multiple images (or channels) associated with a
single coordinate system.</p>
<pre class="r watch-out"><code>library(magick)
image &lt;- list(DAPI = image_read(&quot;DAPI.tif&quot;),
              CD45 = image_read(&quot;CD45.tif&quot;))

vr_object&lt;- formVoltRon(data = intensity_data,
                        metadata = metadata,
                        image = image,
                        coords = coordinates,
                        main.assay = &quot;MELC&quot;,
                        assay.type = &quot;cell&quot;,
                        sample_name = &quot;control_case_3&quot;,
                        image_name = &quot;MELC&quot;)</code></pre>
<p>These channels then can be interrogated and used as background images
for spatial plots and spatial feature plots as well.</p>
<pre class="r watch-out"><code>vrImageChannelNames(vr_object)</code></pre>
<pre><code>       Assay    Layer         Sample Spatial  Channels
Assay1  MELC Section1 control_case_3    MELC DAPI,CD45</code></pre>
<p>You can extract each of these channels individually.</p>
<pre class="r watch-out"><code>vrImages(vr_object, name = &quot;MELC&quot;, channel = &quot;DAPI&quot;)
vrImages(vr_object, name = &quot;MELC&quot;, channel = &quot;CD45&quot;)</code></pre>
<table>
<tr>
<td>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/importdata_DAPI.png" class="center">
</td>
<td>
<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/importdata_CD45.png" class="center">
</td>
</tr>
</table>
<p></br></p>
</div>
<div id="multiplex-if-qupath" class="section level2">
<h2>Multiplex IF (QuPath)</h2>
<p>VoltRon supports the analysis of clustering cells captured from
multiplex immunofluorescence (IF) experiment that typically captured and
stored in ome.tiff and/or qptiff files of high-resolution images. To
process and segment single cells as well as quantifying intensity of
protein markers, we can use <a
href="https://qupath.github.io/">QuPath</a> software. Extensions of
QuPath such as InstanSeg and StarDist could be used to process images,
which we then import into VoltRon to build multiple IF assays.</p>
<p>QuPath allows you do select an ROI, and then the users can go to
<strong>Extensions -&gt; InstanSeg -&gt; Run InstanSeg</strong>. The
pane of InstanSeg let you choose the model for segmentation, device (mps
and cuda for gpu support) and the channels to learn the segmentation and
calculating features. Once complete, <strong>(i)</strong> the feature x
segments (cell) matrix can be exported from <strong>Measurements -&gt;
Show Detection Measurements -&gt; save* as a text file, </strong>(ii)**
the segments are exported from <strong>Export objects as
GeoJSON</strong> excluding measurements and exporting as
FeatureCollection.</p>
<p><img width="100%" height="100%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/import_qupath.png" class="center"></p>
<p>With these files, we can use the <strong>importQuPathIF</strong>
function to import the data as a VoltRon object. You can select the
resolution of the channels using <strong>series</strong> and
<strong>resolution</strong> parameters which will pick the desired level
from the ome.tiff file.</p>
<pre class="r watch-out"><code>adj_vr &lt;- importQuPathIF(measurements = &quot;measurements.txt&quot;,
                         segments = &quot;measurements.geojson&quot;, 
                         image = &quot;if_exp.ome.tif&quot;, 
                         channels = c(&quot;DAPI&quot;, &quot;CD20&quot;, &quot;CD21&quot;), 
                         series = 1,
                         resolution = 1, 
                         sample_name = &quot;IFdata&quot;)</code></pre>
<p>You can use the following function to get the names of all channels
in the ome.tiff file</p>
<pre class="r watch-out"><code>getOmeTiffChannels(if_exp.ome.tif)</code></pre>
<p></br></p>
</div>
<div id="image-only-voltron-objects" class="section level2">
<h2>Image-only VoltRon objects</h2>
<p>With VoltRon we can also build objects where pixels (or tiles) are
defined as spatial points. These information are derived from images
only which then can be used for multiple downstream analysis
purposes.</p>
<p>For this we incorporate <strong>importImageData</strong> function and
only supply an image object. We will use the H&amp;E image derived from
a tissue section that was first analyzed by The 10x Genomics <a
href="https://www.10xgenomics.com/platforms/xenium">Xenium In Situ</a>
platform.</p>
<p>More information on the Xenium and the study can be also be found on
the <a
href="https://www.biorxiv.org/content/10.1101/2022.10.06.510405v1">bioRxiv
preprint</a>. You can download the H&amp;E image from the <a
href="https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast">10x
Genomics website</a> as well (specifically, import the
<strong>Post-Xenium H&amp;E image (TIFF)</strong> data).</p>
<pre class="r watch-out"><code>Xen_R1_image &lt;- importImageData(&quot;Xenium_FFPE_Human_Breast_Cancer_Rep1_he_image.tif&quot;,
                                sample_name = &quot;XeniumR1image&quot;, 
                                image_name = &quot;H&amp;E&quot;)
Xen_R1_image</code></pre>
<pre><code>VoltRon Object 
XeniumR1image: 
  Layers: Section1 
Assays: ImageData(Main) </code></pre>
<pre class="r watch-out"><code>vrImages(Xen_R1_image)</code></pre>
<p><img width="70%" height="70%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/importdata_HE.png" class="center"></p>
<p></br></p>
<div id="ome-tiff" class="section level3">
<h3>OME-TIFF</h3>
<p>You can also import images from OME.TIFF files directly. Since these
files often come in shape of <a
href="https://en.wikipedia.org/wiki/Pyramid_(image_processing)">image
pyramids</a>, we need to use <strong>RBioFormats</strong> the package.
The <code>read.metadata</code> function will allow you to browse the
existing resolutions and series in the image.</p>
<p>RBioFormats requires rJava and JDK installed, see <a
href="https://github.com/BIMSBbioinfo/VoltRon?tab=readme-ov-file#dependencies">dependencies</a>
section for more information.</p>
<p>We will use the post-Xenium OME.TIFF files from the <a
href="https://www.10xgenomics.com/datasets/xenium-prime-ffpe-neonatal-mouse">Whole
Mouse Pup slide</a> from the 10X Genomics website. Please download the
OME.TIFF file from output files.</p>
<pre class="r watch-out"><code># dependencies
if(!requireNamespace(&quot;RBioFormats&quot;))
  BiocManager::install(&quot;RBioFormats&quot;)
library(RBioFormats)

# import image
ome.tiff &lt;- &quot;Xenium_Prime_Mouse_Pup_FFPE_he_image.ome.tif&quot;
read.metadata(ome.tiff)</code></pre>
<pre><code>ImageMetadata list of length 10 

 series res sizeX sizeY sizeC sizeZ sizeT total
 1      1   90959 62008 3     1     1     3    
 1      2   45479 31004 3     1     1     3    
 1      3   22739 15502 3     1     1     3    
 1      4   11369 7751  3     1     1     3    
 1      5   5684  3875  3     1     1     3    
 1      6   2842  1937  3     1     1     3    
 1      7   1421  968   3     1     1     3    
 1      8   710   484   3     1     1     3    
 1      9   355   242   3     1     1     3    
 1      10  177   121   3     1     1     3    

globalMetadata:List of 1525
 $ 20x_BF_01 Microscope Autoexposure enabled             : chr &quot;0&quot;
 $ 20x_BF_01 Value #359                                  : chr &quot;(42753.440890479455, 8472.726448134907)&quot;
 $ 20x_BF_01 Value #358                                  : chr &quot;-122.4&quot;
 $ 20x_BF_01 Units #049                                  : chr &quot;10^-6m^1&quot;
 $ 20x_BF_01 Value #357                                  : chr &quot;0&quot;
  [list output truncated]</code></pre>
<p></br></p>
<p>Now, we can specify the <code>series</code> and
<code>resolution</code> to select the image layer we want to import to
VoltRon.</p>
<pre class="r watch-out"><code>vrimagedata &lt;- importImageData(ome.tiff, series = 1, resolution = 5)
vrImages(vrimagedata)</code></pre>
<p><img width="80%" height="80%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/importdata_HE_OMETIFF.png" class="center"></p>
<p></br></p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
